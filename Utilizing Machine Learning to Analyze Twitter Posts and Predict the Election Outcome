#libraries for tweet extraction
import tweepy as tw
import pandas as pd
import numpy as np

#keys recieved from your Twitter APO
consumer_key = ''
consumer_secret = ''
access_token = ''
access_secret = ''

#API authentication (Connecting Python and Tweepy)
auth = tw.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_secret)
api = tw.API(auth, wait_on_rate_limit=True)

#searching Twitter and creating a dataframe
search = "(david OR perdue OR jon OR ossoff OR david perdue OR jon ossoff)"
query = tw.Cursor(api.search, q=search).items(2000)
tweets = [{'Tweet':tweet.text, 'Timestamp':tweet.created_at} for tweet in query]
df = pd.DataFrame.from_dict(tweets)

#setting mentions/references
perdue_ref = ['DavidPerdue', 'David Perdue', 'David', 'Perdue', 'Perdue\'s', 'perdue', 'david']
ossoff_ref = ['JonOssoff', 'Jon Ossoff', 'Jon', 'Ossoff', 'Ossoff\'s', 'ossoff','jon' ]

#identify the subject
def identify_subject(tweet, refs):
    flag = 0 
    for ref in refs:
        if tweet.find(ref) != -1:
            flag = 1
    return flag
    
    #adding mention values to the dataframe
df['Perdue'] = df['Tweet'].apply(lambda x: identify_subject(x, perdue_ref)) 
df['Ossoff'] = df['Tweet'].apply(lambda x: identify_subject(x, ossoff_ref))
df.head()

#libraries for preprocessing and sentiment analysis
import nltk
from nltk.corpus import stopwords
from textblob import Word, TextBlob
nltk.download('stopwords')
nltk.download('wordnet')
stop_words = stopwords.words('english')
custom_stopwords = ['RT']

#preprocess tweets(cleaning up)
def preprocess_tweets(tweet, custom_stopwords):
    processed_tweet = tweet
    processed_tweet.replace('[^\w\s]', '')
    processed_tweet = " ".join(word for word in processed_tweet.split() if word not in stop_words)
    processed_tweet = " ".join(word for word in processed_tweet.split() if word not in custom_stopwords)
    processed_tweet = " ".join(Word(word).lemmatize() for word in processed_tweet.split())
    return(processed_tweet)

df['Processed Tweet'] = df['Tweet'].apply(lambda x: preprocess_tweets(x, custom_stopwords))

# Calculate polarity
df['polarity'] = df['Processed Tweet'].apply(lambda x: TextBlob(x).sentiment[0])
df.head(10)

perdue_stats = df[df['Perdue']==1][['Perdue','polarity']].groupby('Perdue').agg([np.mean, np.max, np.min, np.median])
ossoff_stats = df[df['Ossoff']==1][['Ossoff','polarity']].groupby('Ossoff').agg([np.mean, np.max, np.min, np.median])

pmean = df[df['Perdue']==1][['Perdue','polarity']].groupby('Perdue').agg([np.mean])
omean = df[df['Ossoff']==1][['Ossoff','polarity']].groupby('Ossoff').agg([np.mean])

ossoff = df[df['Ossoff']==1][['Timestamp', 'polarity']]
ossoff = ossoff.sort_values(by='Timestamp', ascending=True)
ossoff['MA Polarity'] = ossoff.polarity.rolling(10, min_periods=3).mean()

perdue = df[df['Perdue']==1][['Timestamp', 'polarity']]
perdue = perdue.sort_values(by='Timestamp', ascending=True)
perdue['MA Polarity'] = perdue.polarity.rolling(10, min_periods=3).mean()

from matplotlib import pyplot as plt

repub = 'red'
demo = 'blue'
fig, axes = plt.subplots(2, 1, figsize=(13, 10))

axes[0].plot(ossoff['Timestamp'], ossoff['MA Polarity'])
axes[0].set_title("\n".join(["Ossoff Polarity"]))
axes[1].plot(perdue['Timestamp'], perdue['MA Polarity'], color='red')
axes[1].set_title("\n".join(["Perdue Polarity"]))

fig.suptitle("\n".join(["Georgia Runoff Sentiment Analysis"]), y=0.98)

plt.show()

plt.boxplot(perdue_stats)
print(pmean)
